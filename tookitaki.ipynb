{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (12,20,63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df1_i = pd.read_csv('raw_account_70_new.csv')\n",
    "df1_t = pd.read_csv('raw_account_30_new.csv')\n",
    "df2_i = pd.read_csv('raw_data_70_new.csv')\n",
    "df2_t = pd.read_csv('raw_data_30_new.csv')\n",
    "df3_i = pd.read_csv('raw_enquiry_70_new.csv')\n",
    "df3_t = pd.read_csv('raw_enquiry_30_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing customer number repitition\n",
    "c_1 = df1_i['customer_no'] + 13000\n",
    "c_2 = df2_i['customer_no'] + 13000\n",
    "c_3 = df3_i['customer_no'] + 13000\n",
    "df1_i['customer_no'] = c_1\n",
    "df2_i['customer_no'] = c_2\n",
    "df3_i['customer_no'] = c_3\n",
    "\n",
    "\n",
    "len_1 = len(df1_i)\n",
    "len_2 = len(df2_i)\n",
    "len_3 = len(df3_i)\n",
    "df1 = pd.concat([df1_i,df1_t],axis=0)\n",
    "df2 = pd.concat([df2_i,df2_t],axis=0)\n",
    "df3 = pd.concat([df3_i,df3_t],axis=0)\n",
    "\n",
    "coll = [df1,df2,df3]\n",
    "for i in coll:\n",
    "    i.reset_index(inplace= True)\n",
    "    i.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 265897 entries, 0 to 265896\n",
      "Data columns (total 21 columns):\n",
      "dt_opened              265897 non-null datetime64[ns]\n",
      "customer_no            265897 non-null int64\n",
      "upload_dt              265897 non-null datetime64[ns]\n",
      "acct_type              265897 non-null int64\n",
      "owner_indic            265897 non-null int64\n",
      "opened_dt              265268 non-null datetime64[ns]\n",
      "last_paymt_dt          229707 non-null datetime64[ns]\n",
      "closed_dt              110179 non-null datetime64[ns]\n",
      "reporting_dt           265897 non-null datetime64[ns]\n",
      "high_credit_amt        253327 non-null float64\n",
      "cur_balance_amt        265897 non-null int64\n",
      "amt_past_due           1274 non-null float64\n",
      "paymenthistory1        265897 non-null object\n",
      "paymenthistory2        111774 non-null object\n",
      "paymt_str_dt           265895 non-null datetime64[ns]\n",
      "paymt_end_dt           265895 non-null datetime64[ns]\n",
      "creditlimit            69344 non-null float64\n",
      "cashlimit              50027 non-null float64\n",
      "rateofinterest         35340 non-null float64\n",
      "paymentfrequency       90924 non-null float64\n",
      "actualpaymentamount    58316 non-null float64\n",
      "dtypes: datetime64[ns](8), float64(7), int64(4), object(2)\n",
      "memory usage: 42.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#prepocessing df1\n",
    "col_dates_1 = ['dt_opened', 'upload_dt','opened_dt', 'last_paymt_dt', 'closed_dt',\n",
    "             'reporting_dt','paymt_str_dt', 'paymt_end_dt']\n",
    "for col in col_dates_1:\n",
    "    df1[col] = pd.to_datetime(df1[col])\n",
    "\n",
    "roi = []\n",
    "for i in df1.rateofinterest:\n",
    "    try:\n",
    "        roi.append(float(i.replace('\"','')))\n",
    "    except:\n",
    "        roi.append(i)\n",
    "df1['rateofinterest'] = roi\n",
    "df1['rateofinterest'] = df1.rateofinterest.astype('float')\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq</th>\n",
       "      <th>nulls</th>\n",
       "      <th>dty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dt_opened</th>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_no</th>\n",
       "      <td>34136</td>\n",
       "      <td>0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry_time</th>\n",
       "      <td>304</td>\n",
       "      <td>24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_1</th>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_2</th>\n",
       "      <td>289</td>\n",
       "      <td>4047</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_3</th>\n",
       "      <td>272</td>\n",
       "      <td>4047</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_4</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_5</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_6</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_7</th>\n",
       "      <td>513</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_8</th>\n",
       "      <td>22</td>\n",
       "      <td>32343</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_9</th>\n",
       "      <td>22</td>\n",
       "      <td>32343</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_10</th>\n",
       "      <td>14</td>\n",
       "      <td>34065</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_11</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_12</th>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_13</th>\n",
       "      <td>17</td>\n",
       "      <td>18522</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_14</th>\n",
       "      <td>3</td>\n",
       "      <td>10996</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_15</th>\n",
       "      <td>422</td>\n",
       "      <td>37</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_16</th>\n",
       "      <td>618</td>\n",
       "      <td>39</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_17</th>\n",
       "      <td>388</td>\n",
       "      <td>32681</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_18</th>\n",
       "      <td>18</td>\n",
       "      <td>34105</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_19</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_20</th>\n",
       "      <td>12384</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_21</th>\n",
       "      <td>9565</td>\n",
       "      <td>24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_22</th>\n",
       "      <td>3762</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_23</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_24</th>\n",
       "      <td>975</td>\n",
       "      <td>916</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_25</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_26</th>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_27</th>\n",
       "      <td>12</td>\n",
       "      <td>5170</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_51</th>\n",
       "      <td>11</td>\n",
       "      <td>16338</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_52</th>\n",
       "      <td>758</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_53</th>\n",
       "      <td>198</td>\n",
       "      <td>16594</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_54</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_55</th>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_56</th>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_57</th>\n",
       "      <td>3</td>\n",
       "      <td>30705</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_58</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_59</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_60</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_61</th>\n",
       "      <td>14</td>\n",
       "      <td>34121</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_62</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_63</th>\n",
       "      <td>528</td>\n",
       "      <td>24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_64</th>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_65</th>\n",
       "      <td>471</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_66</th>\n",
       "      <td>3671</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_67</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_68</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_69</th>\n",
       "      <td>5958</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_70</th>\n",
       "      <td>134</td>\n",
       "      <td>24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_71</th>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_72</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_73</th>\n",
       "      <td>3</td>\n",
       "      <td>29917</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_74</th>\n",
       "      <td>4</td>\n",
       "      <td>34112</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_75</th>\n",
       "      <td>90</td>\n",
       "      <td>24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_76</th>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_77</th>\n",
       "      <td>3618</td>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_78</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_79</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bad_label</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              uniq  nulls      dty\n",
       "dt_opened      197      0   object\n",
       "customer_no  34136      0    int64\n",
       "entry_time     304     24   object\n",
       "feature_1        8     24   object\n",
       "feature_2      289   4047   object\n",
       "feature_3      272   4047  float64\n",
       "feature_4        4     24  float64\n",
       "feature_5        2     24   object\n",
       "feature_6        2     24  float64\n",
       "feature_7      513     24  float64\n",
       "feature_8       22  32343   object\n",
       "feature_9       22  32343   object\n",
       "feature_10      14  34065   object\n",
       "feature_11       3     24   object\n",
       "feature_12      17     24   object\n",
       "feature_13      17  18522   object\n",
       "feature_14       3  10996  float64\n",
       "feature_15     422     37   object\n",
       "feature_16     618     39   object\n",
       "feature_17     388  32681   object\n",
       "feature_18      18  34105   object\n",
       "feature_19       3     24  float64\n",
       "feature_20   12384      0   object\n",
       "feature_21    9565     24   object\n",
       "feature_22    3762      0   object\n",
       "feature_23       3     24   object\n",
       "feature_24     975    916   object\n",
       "feature_25       3     24  float64\n",
       "feature_26      12     24  float64\n",
       "feature_27      12   5170   object\n",
       "...            ...    ...      ...\n",
       "feature_51      11  16338   object\n",
       "feature_52     758     24  float64\n",
       "feature_53     198  16594   object\n",
       "feature_54       2     24   object\n",
       "feature_55       6     24  float64\n",
       "feature_56      13     24  float64\n",
       "feature_57       3  30705   object\n",
       "feature_58       3     24   object\n",
       "feature_59       3     24   object\n",
       "feature_60       3     24   object\n",
       "feature_61      14  34121   object\n",
       "feature_62       3     24   object\n",
       "feature_63     528     24   object\n",
       "feature_64      31     24  float64\n",
       "feature_65     471     24  float64\n",
       "feature_66    3671     24  float64\n",
       "feature_67       3     24  float64\n",
       "feature_68       4     24  float64\n",
       "feature_69    5958     24  float64\n",
       "feature_70     134     24   object\n",
       "feature_71      15     24  float64\n",
       "feature_72       3     24   object\n",
       "feature_73       3  29917   object\n",
       "feature_74       4  34112  float64\n",
       "feature_75      90     24   object\n",
       "feature_76       6     24  float64\n",
       "feature_77    3618      0   object\n",
       "feature_78       4     24  float64\n",
       "feature_79       3     24   object\n",
       "Bad_label        2      0    int64\n",
       "\n",
       "[83 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for deciding if categorical or numerical\n",
    "uni_df2 = [len(df2[i].unique()) for i in df2]\n",
    "nulls_df2 = [df2[i].isnull().sum() for i in df2]\n",
    "dt_df2 = [df2[i].dtype for i in df2]\n",
    "analyz_df2 = pd.DataFrame([uni_df2,nulls_df2,dt_df2],index=['uniq','nulls','dty'],columns=df2.columns)\n",
    "analyz_df2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# email processing\n",
    "df2.feature_24.fillna(df2.feature_24.mode()[0],inplace= True)\n",
    "bb1 = [i[:5].upper() for i in df2.feature_24]\n",
    "cc1 = [i.split('.')[-1].upper() for i in df2.feature_24]\n",
    "bb2 = [i for i,_ in Counter(bb1).most_common(7)]\n",
    "cc2 = [i for i,_ in Counter(cc1).most_common(6)]\n",
    "bb = [] # contains first part of email\n",
    "for i in bb1:\n",
    "    if i in bb2:\n",
    "        bb.append(i)\n",
    "    else:\n",
    "        bb.append('OTHER')\n",
    "cc = [] # contains second part of email\n",
    "for i in cc1:\n",
    "    if i in cc2:\n",
    "        cc.append(i)\n",
    "    else:\n",
    "        cc.append('OTHER')\n",
    "df2['feature_24'] = cc # can also use bb\n",
    "\n",
    "df2.feature_45.fillna(df2.feature_45.mode()[0],inplace= True)\n",
    "bb1 = [i[:5].upper() for i in df2.feature_45]\n",
    "cc1 = [i.split('.')[-1].upper() for i in df2.feature_45]\n",
    "bb2 = [i for i,_ in Counter(bb1).most_common(7)]\n",
    "cc2 = [i for i,_ in Counter(cc1).most_common(6)]\n",
    "bb = [] # contains first part of email\n",
    "for i in bb1:\n",
    "    if i in bb2:\n",
    "        bb.append(i)\n",
    "    else:\n",
    "        bb.append('OTHER')\n",
    "cc = [] # contains second part of email\n",
    "for i in cc1:\n",
    "    if i in cc2:\n",
    "        cc.append(i)\n",
    "    else:\n",
    "        cc.append('OTHER')\n",
    "df2['feature_45'] = bb # can also use cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['feature_29'] = df2.feature_29//10000 #pincodes \n",
    "df2['feature_66'] = df2.feature_66//10000\n",
    "# used 44 & dropped 28,44,45 because all represent nearly same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dates\n",
    "jan_2016 = pd.to_datetime('Jan-2016')  # Reference Date\n",
    "li_op = []\n",
    "for i in df2.dt_opened:\n",
    "    li_op.append((jan_2016 - pd.to_datetime(i)).days)\n",
    "df2['dt_opened'] = li_op\n",
    "\n",
    "df2.entry_time.fillna(df2.entry_time.mode()[0],inplace=True)\n",
    "li_et = []\n",
    "for i in df2.entry_time:\n",
    "    li_et.append((jan_2016 - pd.to_datetime(i)).days)\n",
    "df2['entry_time'] = li_et\n",
    "\n",
    "df2.feature_2.fillna(df2.feature_2.mode()[0],inplace=True)\n",
    "li_2 = []\n",
    "for i in df2.feature_2:\n",
    "    li_2.append((jan_2016 - pd.to_datetime(i)).days)\n",
    "df2['feature_2'] = li_2\n",
    "\n",
    "df2.feature_21.fillna('1-Jan-86',inplace=True)\n",
    "li_21 = []\n",
    "for i in df2.feature_21:\n",
    "    year_21 = int(i.split('-')[-1])\n",
    "    if year_21<17:\n",
    "        year_21 += 2000\n",
    "    else:\n",
    "        year_21 += 1900\n",
    "    li_21.append(2016 - year_21)\n",
    "df2['feature_21'] = li_21 \n",
    "\n",
    "df2['feature_30'] = df2.feature_30.fillna(df2.feature_30.mode()[0])\n",
    "df2['feature_30'] = 2016 - df2.feature_30\n",
    "\n",
    "df2['feature_39'] = df2.feature_39.replace({0:2015})\n",
    "df2['feature_39'] = df2.feature_39.fillna(df2.feature_39.mode()[0])\n",
    "df2['feature_39'] = 2016 - df2.feature_39\n",
    "\n",
    "df2.feature_53.fillna('16',inplace=True)\n",
    "li_53 = []\n",
    "for i in df2.feature_53:\n",
    "    year_53 = int(i.split('-')[-1])\n",
    "    if year_53<17:\n",
    "        year_53 += 2000\n",
    "    else:\n",
    "        year_53 += 1900\n",
    "    li_53.append(2016 - year_53)\n",
    "df2['feature_53'] = li_53\n",
    "\n",
    "df2.feature_63.fillna(df2.feature_63.mode()[0],inplace=True)\n",
    "df2['feature_63'] = [2016 - int(i[:4]) for i in df2.feature_63]\n",
    "\n",
    "df2.feature_70.replace({'0-0':'1-Jan'},inplace=True)\n",
    "df2.feature_70.fillna('1-Jan',inplace=True)\n",
    "li_70 = []\n",
    "for i in df2.feature_70:\n",
    "    if i[-2:] == '00':\n",
    "        i = '1-' + i[:3] + '-2015'\n",
    "    elif i[0] == '0':\n",
    "        i = '1-' + i.split('-')[-1] + '-2015'\n",
    "    else:\n",
    "        i += '-2015'\n",
    "    li_70.append((jan_2016 - pd.to_datetime(i)).days)\n",
    "df2['feature_70'] = li_70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# designation\n",
    "df2.feature_38.fillna('NAN',inplace=True)\n",
    "aa = (' '.join(df2.feature_38.tolist())).split(' ') # all the designations\n",
    "aa =  [i for i,_ in Counter(aa).most_common(100)] \n",
    "f_38 = pd.DataFrame()\n",
    "for i in aa:\n",
    "     f_38 = pd.concat([f_38,pd.Series([int(i in j.split(' ')) for j in df2.feature_38], name= 'desg_'+ i )],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical vars\n",
    "# not using 24\n",
    "cats = [1,8,11,12,14,19,23,25,27,29,32,33,34,36,37,45,46,48,51,55,56,57,58,59,60,62,66,67,72,73,79] \n",
    "cats = ['feature_' + str(i) for i in cats]\n",
    "num_cats = [14,19,25,29,34,55,56,66,67] #categorical vars dtype float\n",
    "num_cats = ['feature_' + str(i) for i in num_cats]\n",
    "df2[num_cats] = df2[num_cats].astype('str')\n",
    "df2_cats = pd.get_dummies(df2[cats])\n",
    "df2_cats = pd.concat([df2_cats,f_38],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making suggested variables\n",
    "rec_365 = []\n",
    "for i in df3.enquiry_dt:\n",
    "    try:\n",
    "        rec_365.append(i[-2:] == '15')\n",
    "    except:\n",
    "        rec_365.append(False)\n",
    "rdf3 = df3[rec_365]\n",
    "count_enquiry_recency_365 = pd.Series([len(rdf3[rdf3.customer_no == i]) for i in df2.customer_no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dates_3 = ['dt_opened', 'upload_dt', 'enquiry_dt']\n",
    "for col in col_dates_3:\n",
    "    df3[col] = pd.to_datetime(df3[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: RuntimeWarning: divide by zero encountered in true_divide\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "#making suggested variables\n",
    "df1.paymenthistory1.fillna('',inplace=True)\n",
    "df1.paymenthistory2.fillna('',inplace=True)\n",
    "oct_2015 =  pd.to_datetime('1-Oct-2015')\n",
    "\n",
    "rec_90 = df3[df3.enquiry_dt>= oct_2015]\n",
    "\n",
    "count_enquiry_recency_90 = []\n",
    "mean_diff_lastpaymt_opened_dt = []\n",
    "payment_history_avg_dpd_0_29_bucket = []\n",
    "total_diff_lastpaymt_opened_dt = []\n",
    "utilisation_trend = []\n",
    "Ratio_currbalance_creditlimit  = []\n",
    "mean_diff_open_enquiry_dt = []\n",
    "payment_history_mean_length = []\n",
    "max_freq_enquiry = []\n",
    "\n",
    "for cust in df2.customer_no:\n",
    "    aa = df1[df1.customer_no == cust]\n",
    "    zz = df3[df3.customer_no == cust]\n",
    "    cc = []\n",
    "    ee = []\n",
    "#     for k in range(len(aa)):\n",
    "    bb = aa['reporting_dt'] - aa['paymt_str_dt']\n",
    "    dd = aa['last_paymt_dt'] - aa['opened_dt']\n",
    "        \n",
    "    bb = [i.days for i in bb]\n",
    "    dd = [i.days for i in dd]\n",
    "    bb = pd.Series(bb)\n",
    "    total_diff_lastpaymt_opened_dt.append(sum(dd))\n",
    "    mean_diff_lastpaymt_opened_dt.append(np.mean(dd))\n",
    "    payment_history_avg_dpd_0_29_bucket.append(len(bb[bb<=30]))\n",
    "    \n",
    "    cc = []\n",
    "    ee = []\n",
    "    f_1 = []\n",
    "#     for k in range(len(aa)):\n",
    "    try:\n",
    "        utilisation_trend.append(((aa.cur_balance_amt.sum())*(aa.creditlimit.mean() + aa.cashlimit.mean()))/((aa.creditlimit.sum())*(aa.cur_balance_amt.mean())))\n",
    "    except:\n",
    "        utilisation_trend.append(np.NaN)\n",
    "\n",
    "    try:\n",
    "        Ratio_currbalance_creditlimit.append((aa.cur_balance_amt.sum())/(aa.creditlimit.sum()))\n",
    "    except:\n",
    "        Ratio_currbalance_creditlimit.append(np.NaN)\n",
    "    \n",
    "    gg = zz.dt_opened - zz.enquiry_dt\n",
    "    mean_diff_open_enquiry_dt.append(gg.mean().days)\n",
    "    \n",
    "    jj = np.mean([len(i) + len(j) for i,j in zip(aa.paymenthistory1,aa.paymenthistory2)])\n",
    "    payment_history_mean_length.append(jj)\n",
    "    \n",
    "    max_freq_enquiry.append(Counter(zz.enq_purpose).most_common(1)[0][0])\n",
    "    \n",
    "    count_enquiry_recency_90.append(len(rec_90[rec_90.customer_no == cust]))\n",
    "\n",
    "    \n",
    "count_enquiry_recency_90 = pd.Series(count_enquiry_recency_90)\n",
    "max_freq_enquiry = pd.get_dummies(max_freq_enquiry)\n",
    "payment_history_mean_length = pd.Series(payment_history_mean_length)\n",
    "mean_diff_open_enquiry_dt = pd.Series(mean_diff_open_enquiry_dt)\n",
    "Ratio_currbalance_creditlimit = pd.Series(Ratio_currbalance_creditlimit)\n",
    "Ratio_currbalance_creditlimit.replace({np.inf: 2500, -np.inf: -110}, inplace=True)\n",
    "\n",
    "mean_diff_lastpaymt_opened_dt = pd.Series(mean_diff_lastpaymt_opened_dt)\n",
    "payment_history_avg_dpd_0_29_bucket = pd.Series(payment_history_avg_dpd_0_29_bucket)\n",
    "total_diff_lastpaymt_opened_dt = pd.Series(total_diff_lastpaymt_opened_dt)\n",
    "utilisation_trend = pd.Series(utilisation_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df2.Bad_label\n",
    "#dropping columns like phone number or columns with only single value or columns wit lots of NaN \n",
    "df2.drop(['customer_no','feature_5','feature_6','feature_9','feature_10','feature_13','feature_15','feature_16',\n",
    "          'feature_17','feature_18','feature_20','feature_22','feature_24','feature_28',\n",
    "          'feature_31','feature_38','feature_43','feature_44','feature_47','feature_49','feature_50',\n",
    "          'feature_54','feature_61','feature_74','feature_75','feature_77','Bad_label'],axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2_num = pd.concat([df2.drop(cats,axis=1), count_enquiry_recency_90,max_freq_enquiry,payment_history_mean_length,\n",
    "                     mean_diff_open_enquiry_dt,count_enquiry_recency_365,Ratio_currbalance_creditlimit,mean_diff_lastpaymt_opened_dt,\n",
    "                     payment_history_avg_dpd_0_29_bucket,total_diff_lastpaymt_opened_dt, utilisation_trend],axis= 1)\n",
    "df2_num.columns = range(len(df2_num.columns))\n",
    "\n",
    "#removing obvious outliers\n",
    "for col in df2_num:\n",
    "    df2_num[col] = df2_num[col].mask(df2_num[col] - df2_num[col].mean() > 5*(df2_num[col].std()) , df2_num[col].mean() +  5*(df2_num[col].std()) )\n",
    "df2_num.describe().round()\n",
    "df2_num.fillna(df2_num.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "      <td>34136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>106.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>118304.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31787.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3237.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72863.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>42790.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>918.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2544.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>46.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>95.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104000.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3237.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>161.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>139000.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>43000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3237.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>260.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>510589.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>640124.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2836.0</td>\n",
       "      <td>2541.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>22455.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0        1        2        3        4         5        6   \\\n",
       "count  34136.0  34136.0  34136.0  34136.0  34136.0   34136.0  34136.0   \n",
       "mean     106.0    133.0    126.0    723.0      2.0  118304.0     35.0   \n",
       "std       69.0     69.0     68.0     35.0      1.0   72863.0      7.0   \n",
       "min        1.0      8.0      8.0     -1.0      1.0       0.0     19.0   \n",
       "25%       46.0     76.0     74.0    701.0      1.0   73000.0     30.0   \n",
       "50%       95.0    128.0    112.0    723.0      3.0  104000.0     33.0   \n",
       "75%      161.0    188.0    182.0    741.0      3.0  139000.0     38.0   \n",
       "max      260.0    334.0    333.0    896.0      3.0  510589.0     72.0   \n",
       "\n",
       "            7        8         9    ...          43       44       45  \\\n",
       "count  34136.0  34136.0   34136.0   ...     34136.0  34136.0  34136.0   \n",
       "mean       1.0     15.0   31787.0   ...         0.0      0.0     58.0   \n",
       "std        1.0     12.0   42790.0   ...         0.0      0.0     22.0   \n",
       "min        0.0      1.0       1.0   ...         0.0      0.0      9.0   \n",
       "25%        0.0      5.0       1.0   ...         0.0      0.0     41.0   \n",
       "50%        0.0     11.0   30000.0   ...         0.0      0.0     57.0   \n",
       "75%        2.0     24.0   43000.0   ...         0.0      0.0     73.0   \n",
       "max        6.0     52.0  640124.0   ...         0.0      0.0    120.0   \n",
       "\n",
       "            46       47       48       49       50       51       52  \n",
       "count  34136.0  34136.0  34136.0  34136.0  34136.0  34136.0  34136.0  \n",
       "mean     926.0      3.0    410.0    596.0      6.0   3237.0      5.0  \n",
       "std      570.0      4.0    918.0    275.0      4.0   2544.0      3.0  \n",
       "min        8.0      0.0   -110.0      1.0      0.0      1.0      1.0  \n",
       "25%      488.0      1.0      1.0    491.0      3.0   1997.0      3.0  \n",
       "50%      782.0      2.0      2.0    596.0      5.0   3237.0      5.0  \n",
       "75%     1262.0      5.0     11.0    596.0      8.0   3237.0      5.0  \n",
       "max     3530.0     22.0   2836.0   2541.0     28.0  22455.0     26.0  \n",
       "\n",
       "[8 rows x 53 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_num.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.000000\n",
       "1       8.000000\n",
       "2       8.000000\n",
       "3      -1.000000\n",
       "4       1.000000\n",
       "5       0.000000\n",
       "6      19.000000\n",
       "7       0.000000\n",
       "8       1.000000\n",
       "9       1.000000\n",
       "10      1.000000\n",
       "11      0.000000\n",
       "12      0.000000\n",
       "13      0.000000\n",
       "14      0.000000\n",
       "15      0.000000\n",
       "16      1.000000\n",
       "17      2.000000\n",
       "18      1.000000\n",
       "19      1.000000\n",
       "20      1.000000\n",
       "21     61.000000\n",
       "22      2.000000\n",
       "23      0.000000\n",
       "24      1.000000\n",
       "25      0.000000\n",
       "26      0.000000\n",
       "27      0.000000\n",
       "28      0.000000\n",
       "29      0.000000\n",
       "30      0.000000\n",
       "31      0.000000\n",
       "32      0.000000\n",
       "33      0.000000\n",
       "34      0.000000\n",
       "35      0.000000\n",
       "36      0.000000\n",
       "37      0.000000\n",
       "38      0.000000\n",
       "39      0.000000\n",
       "40      0.000000\n",
       "41      0.000000\n",
       "42      0.000000\n",
       "43      0.000000\n",
       "44      0.000000\n",
       "45      9.000000\n",
       "46      8.000000\n",
       "47      0.000000\n",
       "48   -110.000000\n",
       "49      1.000000\n",
       "50      0.000000\n",
       "51      1.000000\n",
       "52      1.000007\n",
       "Name: min, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_num.describe().loc['min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34136, 479)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmsc = MinMaxScaler(feature_range=(0,1))\n",
    "X = mmsc.fit_transform(df2_num)\n",
    "X = np.concatenate([X,df2_cats.values],axis = 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:len_2]\n",
    "X_test = X[len_2:]\n",
    "y_train = label.values[:len_2]\n",
    "y_test = label.values[len_2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV ,cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "param_grid = [{'n_estimators':[20,50,80],'max_features':[0.85,0.9,0.95,1.0],'max_depth':[None,2,5,6]}]\n",
    "gsear = GridSearchCV(clf,param_grid, n_jobs = -1,cv = 4, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'n_estimators': [20, 50, 80], 'max_features': [0.85, 0.9, 0.95, 1.0], 'max_depth': [None, 2, 5, 6]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsear.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6320337207869553"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsear.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2, 'max_features': 0.95, 'n_estimators': 80}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsear.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.40674415739106\n"
     ]
    }
   ],
   "source": [
    "gini_coeff = 100*(2*gsear.best_score_ - 1)\n",
    "print(gini_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.00451282, 0.00682094, 0.        ,\n",
       "       0.47156255, 0.00698243, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.04667333,\n",
       "       0.00885015, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01163824, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.02397702,\n",
       "       0.        , 0.        , 0.        , 0.00681627, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01210544, 0.05854731, 0.08785711, 0.05775873, 0.04201434,\n",
       "       0.00384225, 0.00746829, 0.00340829, 0.02404765, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00340963, 0.        , 0.00280034, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01106296, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00213078, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.03441866, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00359519, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00275676,\n",
       "       0.        , 0.        , 0.        , 0.00261215, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00264503,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00300837,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.002023  , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00295931, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00873293, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00454384, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00164697, 0.00312108, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00620415, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00260295, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00306521, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00237434, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00205151, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00389688,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00345478, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsear.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(gsear.best_estimator_.feature_importances_ > 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_p = PCA(n_components= 70).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-b2c57b05308e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf2\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mX_p\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             return_times=True)\n\u001b[1;32m--> 206\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 328\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    791\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf2 = RandomForestClassifier(max_depth= None, n_estimators= 1000)\n",
    "cross_val_score(clf2 , X_p , label,scoring='roc_auc',cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 1.,1: 23.3}\n",
    "model1 = models.Sequential()\n",
    "model1.add(layers.Dense(512,activation='relu',input_shape = (479,)))\n",
    "model1.add(layers.Dropout(0.2))\n",
    "model1.add(layers.Dense(512, activation='relu'))\n",
    "model1.add(layers.Dropout(0.2))\n",
    "model1.add(layers.Dense(128,activation= 'relu'))\n",
    "model1.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model1.compile(loss='binary_crossentropy', optimizer='Adam', metrics =['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23895 samples, validate on 10241 samples\n",
      "Epoch 1/500\n",
      "23895/23895 [==============================] - 7s 286us/step - loss: 0.2063 - acc: 0.9680 - val_loss: 4.3524 - val_acc: 0.8750\n",
      "Epoch 2/500\n",
      "23895/23895 [==============================] - 7s 286us/step - loss: 0.2042 - acc: 0.9682 - val_loss: 4.3732 - val_acc: 0.8896\n",
      "Epoch 3/500\n",
      "23895/23895 [==============================] - 7s 300us/step - loss: 0.2074 - acc: 0.9700 - val_loss: 5.0172 - val_acc: 0.8855\n",
      "Epoch 4/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1807 - acc: 0.9697 - val_loss: 4.7332 - val_acc: 0.8900\n",
      "Epoch 5/500\n",
      "23895/23895 [==============================] - 7s 314us/step - loss: 0.1928 - acc: 0.9682 - val_loss: 4.5538 - val_acc: 0.8785\n",
      "Epoch 6/500\n",
      "23895/23895 [==============================] - 7s 308us/step - loss: 0.1888 - acc: 0.9694 - val_loss: 4.7283 - val_acc: 0.8755\n",
      "Epoch 7/500\n",
      "23895/23895 [==============================] - 7s 305us/step - loss: 0.2166 - acc: 0.9691 - val_loss: 3.8367 - val_acc: 0.8765\n",
      "Epoch 8/500\n",
      "23895/23895 [==============================] - 7s 313us/step - loss: 0.1931 - acc: 0.9701 - val_loss: 4.2291 - val_acc: 0.8707\n",
      "Epoch 9/500\n",
      "23895/23895 [==============================] - 8s 315us/step - loss: 0.1973 - acc: 0.9705 - val_loss: 4.6723 - val_acc: 0.8890\n",
      "Epoch 10/500\n",
      "23895/23895 [==============================] - 8s 327us/step - loss: 0.1921 - acc: 0.9718 - val_loss: 4.0656 - val_acc: 0.8673\n",
      "Epoch 11/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.1802 - acc: 0.9733 - val_loss: 5.6283 - val_acc: 0.9060\n",
      "Epoch 12/500\n",
      "23895/23895 [==============================] - 8s 314us/step - loss: 0.2094 - acc: 0.9710 - val_loss: 4.8592 - val_acc: 0.8997\n",
      "Epoch 13/500\n",
      "23895/23895 [==============================] - 8s 316us/step - loss: 0.2069 - acc: 0.9734 - val_loss: 4.7250 - val_acc: 0.8873\n",
      "Epoch 14/500\n",
      "23895/23895 [==============================] - 8s 314us/step - loss: 0.1890 - acc: 0.9737 - val_loss: 4.8852 - val_acc: 0.8910\n",
      "Epoch 15/500\n",
      "23895/23895 [==============================] - 8s 314us/step - loss: 0.1718 - acc: 0.9756 - val_loss: 4.8321 - val_acc: 0.8949\n",
      "Epoch 16/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.1547 - acc: 0.9756 - val_loss: 4.8058 - val_acc: 0.8925\n",
      "Epoch 17/500\n",
      "23895/23895 [==============================] - 8s 315us/step - loss: 0.1906 - acc: 0.9716 - val_loss: 5.1919 - val_acc: 0.8921\n",
      "Epoch 18/500\n",
      "23895/23895 [==============================] - 8s 315us/step - loss: 0.1927 - acc: 0.9691 - val_loss: 5.1004 - val_acc: 0.8934\n",
      "Epoch 19/500\n",
      "23895/23895 [==============================] - 8s 314us/step - loss: 0.1873 - acc: 0.9715 - val_loss: 5.1383 - val_acc: 0.8902\n",
      "Epoch 20/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.1636 - acc: 0.9754 - val_loss: 4.5954 - val_acc: 0.8932\n",
      "Epoch 21/500\n",
      "23895/23895 [==============================] - 8s 326us/step - loss: 0.1710 - acc: 0.9728 - val_loss: 5.5650 - val_acc: 0.8922\n",
      "Epoch 22/500\n",
      "23895/23895 [==============================] - 8s 326us/step - loss: 0.2040 - acc: 0.9725 - val_loss: 4.7313 - val_acc: 0.8819\n",
      "Epoch 23/500\n",
      "23895/23895 [==============================] - 8s 316us/step - loss: 0.2112 - acc: 0.9725 - val_loss: 5.2339 - val_acc: 0.8920\n",
      "Epoch 24/500\n",
      "23895/23895 [==============================] - 8s 316us/step - loss: 0.1763 - acc: 0.9749 - val_loss: 5.0947 - val_acc: 0.8915\n",
      "Epoch 25/500\n",
      "23895/23895 [==============================] - 8s 316us/step - loss: 0.1576 - acc: 0.9775 - val_loss: 4.8326 - val_acc: 0.8941\n",
      "Epoch 26/500\n",
      "23895/23895 [==============================] - 8s 316us/step - loss: 0.1936 - acc: 0.9734 - val_loss: 3.1866 - val_acc: 0.8706\n",
      "Epoch 27/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.1976 - acc: 0.9746 - val_loss: 5.2050 - val_acc: 0.8923\n",
      "Epoch 28/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.1741 - acc: 0.9745 - val_loss: 5.1349 - val_acc: 0.9000\n",
      "Epoch 29/500\n",
      "23895/23895 [==============================] - 8s 316us/step - loss: 0.1833 - acc: 0.9730 - val_loss: 5.2123 - val_acc: 0.8818\n",
      "Epoch 30/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.1742 - acc: 0.9751 - val_loss: 5.0950 - val_acc: 0.8951\n",
      "Epoch 31/500\n",
      "23895/23895 [==============================] - 8s 317us/step - loss: 0.1948 - acc: 0.9755 - val_loss: 4.4614 - val_acc: 0.8833\n",
      "Epoch 32/500\n",
      "23895/23895 [==============================] - 8s 324us/step - loss: 0.1674 - acc: 0.9749 - val_loss: 5.4870 - val_acc: 0.9099\n",
      "Epoch 33/500\n",
      "23895/23895 [==============================] - 8s 316us/step - loss: 0.2073 - acc: 0.9751 - val_loss: 4.7847 - val_acc: 0.8910\n",
      "Epoch 34/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.1876 - acc: 0.9778 - val_loss: 4.9494 - val_acc: 0.8919\n",
      "Epoch 35/500\n",
      "23895/23895 [==============================] - 8s 317us/step - loss: 0.1681 - acc: 0.9781 - val_loss: 5.1340 - val_acc: 0.8931\n",
      "Epoch 36/500\n",
      "23895/23895 [==============================] - 8s 323us/step - loss: 0.1836 - acc: 0.9742 - val_loss: 5.7387 - val_acc: 0.8995\n",
      "Epoch 37/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.2057 - acc: 0.9720 - val_loss: 4.9002 - val_acc: 0.8924\n",
      "Epoch 38/500\n",
      "23895/23895 [==============================] - 8s 319us/step - loss: 0.1800 - acc: 0.9759 - val_loss: 5.3431 - val_acc: 0.8939\n",
      "Epoch 39/500\n",
      "23895/23895 [==============================] - 8s 319us/step - loss: 0.1643 - acc: 0.9763 - val_loss: 5.4336 - val_acc: 0.8946\n",
      "Epoch 40/500\n",
      "23895/23895 [==============================] - 8s 319us/step - loss: 0.1951 - acc: 0.9773 - val_loss: 5.1620 - val_acc: 0.8881\n",
      "Epoch 41/500\n",
      "23895/23895 [==============================] - 8s 320us/step - loss: 0.1911 - acc: 0.9745 - val_loss: 4.7534 - val_acc: 0.8883\n",
      "Epoch 42/500\n",
      "23895/23895 [==============================] - 8s 319us/step - loss: 0.1565 - acc: 0.9776 - val_loss: 5.4948 - val_acc: 0.8888\n",
      "Epoch 43/500\n",
      "23895/23895 [==============================] - 8s 327us/step - loss: 0.1742 - acc: 0.9764 - val_loss: 4.8254 - val_acc: 0.8877\n",
      "Epoch 44/500\n",
      "23895/23895 [==============================] - 8s 321us/step - loss: 0.1476 - acc: 0.9808 - val_loss: 5.2850 - val_acc: 0.8931\n",
      "Epoch 45/500\n",
      "23895/23895 [==============================] - 8s 316us/step - loss: 0.2083 - acc: 0.9743 - val_loss: 5.3043 - val_acc: 0.8959\n",
      "Epoch 46/500\n",
      "23895/23895 [==============================] - 8s 317us/step - loss: 0.1384 - acc: 0.9832 - val_loss: 5.4279 - val_acc: 0.8975\n",
      "Epoch 47/500\n",
      "23895/23895 [==============================] - 8s 317us/step - loss: 0.1563 - acc: 0.9800 - val_loss: 5.3999 - val_acc: 0.8997\n",
      "Epoch 48/500\n",
      "23895/23895 [==============================] - 8s 317us/step - loss: 0.1896 - acc: 0.9798 - val_loss: 4.4198 - val_acc: 0.8900\n",
      "Epoch 49/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.1805 - acc: 0.9789 - val_loss: 5.2009 - val_acc: 0.8913\n",
      "Epoch 50/500\n",
      "23895/23895 [==============================] - 8s 319us/step - loss: 0.1493 - acc: 0.9812 - val_loss: 5.2725 - val_acc: 0.8980\n",
      "Epoch 51/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.1812 - acc: 0.9813 - val_loss: 4.8130 - val_acc: 0.8803\n",
      "Epoch 52/500\n",
      "23895/23895 [==============================] - 8s 322us/step - loss: 0.1760 - acc: 0.9816 - val_loss: 4.7360 - val_acc: 0.8912\n",
      "Epoch 53/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.1717 - acc: 0.9809 - val_loss: 4.7727 - val_acc: 0.8922\n",
      "Epoch 54/500\n",
      "23895/23895 [==============================] - 8s 320us/step - loss: 0.1625 - acc: 0.9805 - val_loss: 5.1749 - val_acc: 0.8917\n",
      "Epoch 55/500\n",
      "23895/23895 [==============================] - 8s 319us/step - loss: 0.2037 - acc: 0.9777 - val_loss: 5.0986 - val_acc: 0.8932\n",
      "Epoch 56/500\n",
      "23895/23895 [==============================] - 8s 319us/step - loss: 0.1594 - acc: 0.9806 - val_loss: 5.0336 - val_acc: 0.8868\n",
      "Epoch 57/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.2023 - acc: 0.9763 - val_loss: 4.3245 - val_acc: 0.8777\n",
      "Epoch 58/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.2085 - acc: 0.9772 - val_loss: 4.9509 - val_acc: 0.8796\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23895/23895 [==============================] - 7s 306us/step - loss: 0.1895 - acc: 0.9784 - val_loss: 4.6404 - val_acc: 0.8883\n",
      "Epoch 60/500\n",
      "23895/23895 [==============================] - 7s 303us/step - loss: 0.1727 - acc: 0.9806 - val_loss: 4.7585 - val_acc: 0.8875\n",
      "Epoch 61/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1636 - acc: 0.9823 - val_loss: 5.2784 - val_acc: 0.8942\n",
      "Epoch 62/500\n",
      "23895/23895 [==============================] - 8s 315us/step - loss: 0.1683 - acc: 0.9791 - val_loss: 5.2035 - val_acc: 0.8964\n",
      "Epoch 63/500\n",
      "23895/23895 [==============================] - 7s 308us/step - loss: 0.1724 - acc: 0.9819 - val_loss: 5.2304 - val_acc: 0.8971\n",
      "Epoch 64/500\n",
      "23895/23895 [==============================] - 7s 307us/step - loss: 0.1754 - acc: 0.9804 - val_loss: 4.6974 - val_acc: 0.8860\n",
      "Epoch 65/500\n",
      "23895/23895 [==============================] - 7s 307us/step - loss: 0.1520 - acc: 0.9825 - val_loss: 4.8621 - val_acc: 0.8930\n",
      "Epoch 66/500\n",
      "23895/23895 [==============================] - 7s 307us/step - loss: 0.1743 - acc: 0.9807 - val_loss: 5.5101 - val_acc: 0.9022\n",
      "Epoch 67/500\n",
      "23895/23895 [==============================] - 7s 308us/step - loss: 0.2421 - acc: 0.9792 - val_loss: 5.3216 - val_acc: 0.8954\n",
      "Epoch 68/500\n",
      "23895/23895 [==============================] - 7s 308us/step - loss: 0.1869 - acc: 0.9832 - val_loss: 4.9318 - val_acc: 0.8896\n",
      "Epoch 69/500\n",
      "23895/23895 [==============================] - 7s 307us/step - loss: 0.1696 - acc: 0.9825 - val_loss: 5.0535 - val_acc: 0.9022\n",
      "Epoch 70/500\n",
      "23895/23895 [==============================] - 7s 306us/step - loss: 0.1577 - acc: 0.9838 - val_loss: 4.6061 - val_acc: 0.8859\n",
      "Epoch 71/500\n",
      "23895/23895 [==============================] - 7s 308us/step - loss: 0.1460 - acc: 0.9833 - val_loss: 5.2683 - val_acc: 0.8994\n",
      "Epoch 72/500\n",
      "23895/23895 [==============================] - 7s 307us/step - loss: 0.1252 - acc: 0.9844 - val_loss: 5.6982 - val_acc: 0.9020\n",
      "Epoch 73/500\n",
      "23895/23895 [==============================] - 7s 307us/step - loss: 0.1789 - acc: 0.9814 - val_loss: 5.1657 - val_acc: 0.8887\n",
      "Epoch 74/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1956 - acc: 0.9808 - val_loss: 4.6305 - val_acc: 0.8934\n",
      "Epoch 75/500\n",
      "23895/23895 [==============================] - 7s 307us/step - loss: 0.1726 - acc: 0.9843 - val_loss: 4.4187 - val_acc: 0.8819\n",
      "Epoch 76/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.1466 - acc: 0.9824 - val_loss: 5.2043 - val_acc: 0.8958\n",
      "Epoch 77/500\n",
      "23895/23895 [==============================] - 8s 314us/step - loss: 0.1747 - acc: 0.9819 - val_loss: 5.0561 - val_acc: 0.8920\n",
      "Epoch 78/500\n",
      "23895/23895 [==============================] - 8s 317us/step - loss: 0.1456 - acc: 0.9834 - val_loss: 5.0292 - val_acc: 0.8897\n",
      "Epoch 79/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1551 - acc: 0.9839 - val_loss: 5.5018 - val_acc: 0.8883\n",
      "Epoch 80/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1576 - acc: 0.9843 - val_loss: 4.7860 - val_acc: 0.8909\n",
      "Epoch 81/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1448 - acc: 0.9840 - val_loss: 5.1494 - val_acc: 0.8897\n",
      "Epoch 82/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1093 - acc: 0.9880 - val_loss: 5.6037 - val_acc: 0.9040\n",
      "Epoch 83/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1921 - acc: 0.9816 - val_loss: 5.0578 - val_acc: 0.8880\n",
      "Epoch 84/500\n",
      "23895/23895 [==============================] - 7s 312us/step - loss: 0.1516 - acc: 0.9831 - val_loss: 5.1476 - val_acc: 0.8981\n",
      "Epoch 85/500\n",
      "23895/23895 [==============================] - 7s 313us/step - loss: 0.1682 - acc: 0.9859 - val_loss: 5.0277 - val_acc: 0.8966\n",
      "Epoch 86/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1534 - acc: 0.9857 - val_loss: 5.3527 - val_acc: 0.8986\n",
      "Epoch 87/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1768 - acc: 0.9855 - val_loss: 5.1459 - val_acc: 0.8998\n",
      "Epoch 88/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1726 - acc: 0.9833 - val_loss: 5.3110 - val_acc: 0.8987\n",
      "Epoch 89/500\n",
      "23895/23895 [==============================] - 7s 308us/step - loss: 0.1543 - acc: 0.9847 - val_loss: 5.4176 - val_acc: 0.8980\n",
      "Epoch 90/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1524 - acc: 0.9859 - val_loss: 5.3983 - val_acc: 0.8971\n",
      "Epoch 91/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1396 - acc: 0.9879 - val_loss: 5.2678 - val_acc: 0.8927\n",
      "Epoch 92/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1638 - acc: 0.9854 - val_loss: 4.8796 - val_acc: 0.8880\n",
      "Epoch 93/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1395 - acc: 0.9867 - val_loss: 5.8409 - val_acc: 0.9001\n",
      "Epoch 94/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1541 - acc: 0.9854 - val_loss: 5.1221 - val_acc: 0.8927\n",
      "Epoch 95/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1177 - acc: 0.9872 - val_loss: 5.5262 - val_acc: 0.9029\n",
      "Epoch 96/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1586 - acc: 0.9858 - val_loss: 5.4199 - val_acc: 0.8984\n",
      "Epoch 97/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1461 - acc: 0.9870 - val_loss: 5.3828 - val_acc: 0.8960\n",
      "Epoch 98/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1757 - acc: 0.9846 - val_loss: 4.6993 - val_acc: 0.8872\n",
      "Epoch 99/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1561 - acc: 0.9836 - val_loss: 5.4111 - val_acc: 0.8979\n",
      "Epoch 100/500\n",
      "23895/23895 [==============================] - 7s 312us/step - loss: 0.1571 - acc: 0.9846 - val_loss: 3.8566 - val_acc: 0.8898\n",
      "Epoch 101/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1738 - acc: 0.9839 - val_loss: 5.1333 - val_acc: 0.8999\n",
      "Epoch 102/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1665 - acc: 0.9852 - val_loss: 4.9462 - val_acc: 0.8924\n",
      "Epoch 103/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1815 - acc: 0.9856 - val_loss: 5.0440 - val_acc: 0.8847\n",
      "Epoch 104/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1607 - acc: 0.9869 - val_loss: 5.0758 - val_acc: 0.8964\n",
      "Epoch 105/500\n",
      "23895/23895 [==============================] - 8s 316us/step - loss: 0.1554 - acc: 0.9861 - val_loss: 4.8357 - val_acc: 0.8908\n",
      "Epoch 106/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1462 - acc: 0.9867 - val_loss: 5.3045 - val_acc: 0.8942\n",
      "Epoch 107/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1635 - acc: 0.9850 - val_loss: 5.6742 - val_acc: 0.9008\n",
      "Epoch 108/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1527 - acc: 0.9852 - val_loss: 5.3691 - val_acc: 0.8899\n",
      "Epoch 109/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1520 - acc: 0.9872 - val_loss: 5.3093 - val_acc: 0.8962\n",
      "Epoch 110/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.1295 - acc: 0.9865 - val_loss: 5.1891 - val_acc: 0.8967\n",
      "Epoch 111/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1446 - acc: 0.9867 - val_loss: 5.4619 - val_acc: 0.9022\n",
      "Epoch 112/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1709 - acc: 0.9846 - val_loss: 4.9023 - val_acc: 0.8844\n",
      "Epoch 113/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1848 - acc: 0.9854 - val_loss: 5.1980 - val_acc: 0.8959\n",
      "Epoch 114/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1532 - acc: 0.9868 - val_loss: 5.2754 - val_acc: 0.8989\n",
      "Epoch 115/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1634 - acc: 0.9860 - val_loss: 5.2168 - val_acc: 0.8992\n",
      "Epoch 116/500\n",
      "23895/23895 [==============================] - 7s 313us/step - loss: 0.1523 - acc: 0.9871 - val_loss: 4.8662 - val_acc: 0.9030\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23895/23895 [==============================] - 7s 308us/step - loss: 0.1478 - acc: 0.9876 - val_loss: 5.0395 - val_acc: 0.8986\n",
      "Epoch 118/500\n",
      "23895/23895 [==============================] - 7s 303us/step - loss: 0.1538 - acc: 0.9866 - val_loss: 4.9801 - val_acc: 0.8936\n",
      "Epoch 119/500\n",
      "23895/23895 [==============================] - 7s 307us/step - loss: 0.1419 - acc: 0.9882 - val_loss: 5.1432 - val_acc: 0.9010\n",
      "Epoch 120/500\n",
      "23895/23895 [==============================] - 7s 305us/step - loss: 0.1648 - acc: 0.9869 - val_loss: 4.6802 - val_acc: 0.8899\n",
      "Epoch 121/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1740 - acc: 0.9877 - val_loss: 4.9008 - val_acc: 0.9014\n",
      "Epoch 122/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1334 - acc: 0.9872 - val_loss: 5.3632 - val_acc: 0.9020\n",
      "Epoch 123/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1733 - acc: 0.9858 - val_loss: 5.3221 - val_acc: 0.8970\n",
      "Epoch 124/500\n",
      "23895/23895 [==============================] - 7s 305us/step - loss: 0.1479 - acc: 0.9865 - val_loss: 5.3317 - val_acc: 0.8925\n",
      "Epoch 125/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1519 - acc: 0.9891 - val_loss: 5.3523 - val_acc: 0.8896\n",
      "Epoch 126/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1618 - acc: 0.9868 - val_loss: 5.0830 - val_acc: 0.8974\n",
      "Epoch 127/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1489 - acc: 0.9864 - val_loss: 5.0794 - val_acc: 0.8997\n",
      "Epoch 128/500\n",
      "23895/23895 [==============================] - 7s 307us/step - loss: 0.1262 - acc: 0.9884 - val_loss: 5.3422 - val_acc: 0.8973\n",
      "Epoch 129/500\n",
      "23895/23895 [==============================] - 7s 307us/step - loss: 0.1502 - acc: 0.9871 - val_loss: 4.9887 - val_acc: 0.8900\n",
      "Epoch 130/500\n",
      "23895/23895 [==============================] - 7s 306us/step - loss: 0.1580 - acc: 0.9841 - val_loss: 5.3292 - val_acc: 0.9025\n",
      "Epoch 131/500\n",
      "23895/23895 [==============================] - 7s 308us/step - loss: 0.1563 - acc: 0.9869 - val_loss: 5.0947 - val_acc: 0.8930\n",
      "Epoch 132/500\n",
      "23895/23895 [==============================] - 7s 305us/step - loss: 0.1587 - acc: 0.9869 - val_loss: 5.5864 - val_acc: 0.8974\n",
      "Epoch 133/500\n",
      "23895/23895 [==============================] - 7s 308us/step - loss: 0.1492 - acc: 0.9882 - val_loss: 5.3626 - val_acc: 0.8967\n",
      "Epoch 134/500\n",
      "23895/23895 [==============================] - 7s 305us/step - loss: 0.1610 - acc: 0.9879 - val_loss: 5.2148 - val_acc: 0.8942\n",
      "Epoch 135/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1296 - acc: 0.9892 - val_loss: 5.4000 - val_acc: 0.9020\n",
      "Epoch 136/500\n",
      "23895/23895 [==============================] - 7s 306us/step - loss: 0.1366 - acc: 0.9892 - val_loss: 5.3095 - val_acc: 0.8977\n",
      "Epoch 137/500\n",
      "23895/23895 [==============================] - 7s 303us/step - loss: 0.1597 - acc: 0.9870 - val_loss: 5.3807 - val_acc: 0.8993\n",
      "Epoch 138/500\n",
      "23895/23895 [==============================] - 7s 305us/step - loss: 0.1332 - acc: 0.9882 - val_loss: 5.5257 - val_acc: 0.8958\n",
      "Epoch 139/500\n",
      "23895/23895 [==============================] - 7s 303us/step - loss: 0.1415 - acc: 0.9894 - val_loss: 4.8037 - val_acc: 0.8842\n",
      "Epoch 140/500\n",
      "23895/23895 [==============================] - 7s 303us/step - loss: 0.1684 - acc: 0.9872 - val_loss: 5.4954 - val_acc: 0.9023\n",
      "Epoch 141/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1365 - acc: 0.9891 - val_loss: 5.5370 - val_acc: 0.9019\n",
      "Epoch 142/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1472 - acc: 0.9868 - val_loss: 5.3571 - val_acc: 0.8887\n",
      "Epoch 143/500\n",
      "23895/23895 [==============================] - 7s 305us/step - loss: 0.1387 - acc: 0.9884 - val_loss: 5.2699 - val_acc: 0.8986\n",
      "Epoch 144/500\n",
      "23895/23895 [==============================] - 8s 326us/step - loss: 0.1348 - acc: 0.9899 - val_loss: 5.5647 - val_acc: 0.9001\n",
      "Epoch 145/500\n",
      "23895/23895 [==============================] - 7s 313us/step - loss: 0.1479 - acc: 0.9884 - val_loss: 5.4876 - val_acc: 0.8976\n",
      "Epoch 146/500\n",
      "23895/23895 [==============================] - 8s 314us/step - loss: 0.1875 - acc: 0.9884 - val_loss: 5.4945 - val_acc: 0.9004\n",
      "Epoch 147/500\n",
      "23895/23895 [==============================] - 7s 308us/step - loss: 0.1744 - acc: 0.9888 - val_loss: 5.2516 - val_acc: 0.8930\n",
      "Epoch 148/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1310 - acc: 0.9897 - val_loss: 5.4380 - val_acc: 0.9029\n",
      "Epoch 149/500\n",
      "23895/23895 [==============================] - 7s 312us/step - loss: 0.1288 - acc: 0.9890 - val_loss: 5.8363 - val_acc: 0.9031\n",
      "Epoch 150/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1412 - acc: 0.9884 - val_loss: 5.7458 - val_acc: 0.8956\n",
      "Epoch 151/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1506 - acc: 0.9884 - val_loss: 5.6697 - val_acc: 0.8972\n",
      "Epoch 152/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1750 - acc: 0.9869 - val_loss: 5.4656 - val_acc: 0.8974\n",
      "Epoch 153/500\n",
      "23895/23895 [==============================] - 7s 308us/step - loss: 0.1588 - acc: 0.9885 - val_loss: 5.6141 - val_acc: 0.9007\n",
      "Epoch 154/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1514 - acc: 0.9886 - val_loss: 5.4529 - val_acc: 0.8943\n",
      "Epoch 155/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1307 - acc: 0.9899 - val_loss: 5.7458 - val_acc: 0.9042\n",
      "Epoch 156/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1519 - acc: 0.9895 - val_loss: 5.9407 - val_acc: 0.8990\n",
      "Epoch 157/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1893 - acc: 0.9884 - val_loss: 5.5443 - val_acc: 0.8932\n",
      "Epoch 158/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1686 - acc: 0.9880 - val_loss: 5.9249 - val_acc: 0.9022\n",
      "Epoch 159/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1256 - acc: 0.9904 - val_loss: 5.8656 - val_acc: 0.9050\n",
      "Epoch 160/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1487 - acc: 0.9895 - val_loss: 5.0306 - val_acc: 0.8902\n",
      "Epoch 161/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1267 - acc: 0.9888 - val_loss: 5.6654 - val_acc: 0.8988\n",
      "Epoch 162/500\n",
      "23895/23895 [==============================] - 8s 332us/step - loss: 0.1555 - acc: 0.9882 - val_loss: 5.4862 - val_acc: 0.8941\n",
      "Epoch 163/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1568 - acc: 0.9877 - val_loss: 5.4054 - val_acc: 0.8987\n",
      "Epoch 164/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1790 - acc: 0.9891 - val_loss: 5.4056 - val_acc: 0.8975\n",
      "Epoch 165/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1137 - acc: 0.9918 - val_loss: 5.2060 - val_acc: 0.8907\n",
      "Epoch 166/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1325 - acc: 0.9911 - val_loss: 5.4660 - val_acc: 0.8947\n",
      "Epoch 167/500\n",
      "23895/23895 [==============================] - 8s 322us/step - loss: 0.1393 - acc: 0.9907 - val_loss: 4.9745 - val_acc: 0.8916\n",
      "Epoch 168/500\n",
      "23895/23895 [==============================] - 8s 316us/step - loss: 0.1474 - acc: 0.9900 - val_loss: 5.5397 - val_acc: 0.8976\n",
      "Epoch 169/500\n",
      "23895/23895 [==============================] - 8s 317us/step - loss: 0.1311 - acc: 0.9896 - val_loss: 5.7956 - val_acc: 0.8951\n",
      "Epoch 170/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1194 - acc: 0.9899 - val_loss: 5.4431 - val_acc: 0.8996\n",
      "Epoch 171/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1696 - acc: 0.9891 - val_loss: 5.5522 - val_acc: 0.8933\n",
      "Epoch 172/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1564 - acc: 0.9879 - val_loss: 5.1835 - val_acc: 0.8972\n",
      "Epoch 173/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1605 - acc: 0.9903 - val_loss: 5.4297 - val_acc: 0.8915\n",
      "Epoch 174/500\n",
      "23895/23895 [==============================] - 7s 312us/step - loss: 0.1741 - acc: 0.9892 - val_loss: 5.2851 - val_acc: 0.8970\n",
      "Epoch 175/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23895/23895 [==============================] - 7s 305us/step - loss: 0.1485 - acc: 0.9888 - val_loss: 5.4526 - val_acc: 0.9014\n",
      "Epoch 176/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1724 - acc: 0.9878 - val_loss: 4.8576 - val_acc: 0.8911\n",
      "Epoch 177/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1690 - acc: 0.9883 - val_loss: 5.0491 - val_acc: 0.8946\n",
      "Epoch 178/500\n",
      "23895/23895 [==============================] - 7s 303us/step - loss: 0.1384 - acc: 0.9890 - val_loss: 5.2741 - val_acc: 0.8972\n",
      "Epoch 179/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1447 - acc: 0.9893 - val_loss: 5.4385 - val_acc: 0.8989\n",
      "Epoch 180/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1365 - acc: 0.9901 - val_loss: 5.9358 - val_acc: 0.8993\n",
      "Epoch 181/500\n",
      "23895/23895 [==============================] - 7s 306us/step - loss: 0.1583 - acc: 0.9896 - val_loss: 5.3790 - val_acc: 0.8934\n",
      "Epoch 182/500\n",
      "23895/23895 [==============================] - 7s 305us/step - loss: 0.1536 - acc: 0.9884 - val_loss: 5.4083 - val_acc: 0.8985\n",
      "Epoch 183/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1514 - acc: 0.9893 - val_loss: 5.3026 - val_acc: 0.8941\n",
      "Epoch 184/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1657 - acc: 0.9886 - val_loss: 5.2224 - val_acc: 0.8937\n",
      "Epoch 185/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1419 - acc: 0.9905 - val_loss: 5.3071 - val_acc: 0.8928\n",
      "Epoch 186/500\n",
      "23895/23895 [==============================] - 7s 305us/step - loss: 0.1653 - acc: 0.9893 - val_loss: 5.2807 - val_acc: 0.8973\n",
      "Epoch 187/500\n",
      "23895/23895 [==============================] - 7s 303us/step - loss: 0.1401 - acc: 0.9900 - val_loss: 5.5763 - val_acc: 0.9024\n",
      "Epoch 188/500\n",
      "23895/23895 [==============================] - 7s 306us/step - loss: 0.1292 - acc: 0.9908 - val_loss: 5.5899 - val_acc: 0.9052\n",
      "Epoch 189/500\n",
      "23895/23895 [==============================] - 7s 305us/step - loss: 0.1665 - acc: 0.9895 - val_loss: 5.5411 - val_acc: 0.9012\n",
      "Epoch 190/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1929 - acc: 0.9876 - val_loss: 5.3291 - val_acc: 0.8975\n",
      "Epoch 191/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1738 - acc: 0.9874 - val_loss: 5.2693 - val_acc: 0.8984\n",
      "Epoch 192/500\n",
      "23895/23895 [==============================] - 7s 305us/step - loss: 0.2392 - acc: 0.9872 - val_loss: 5.2580 - val_acc: 0.8970\n",
      "Epoch 193/500\n",
      "23895/23895 [==============================] - 7s 305us/step - loss: 0.1413 - acc: 0.9902 - val_loss: 5.5241 - val_acc: 0.8996\n",
      "Epoch 194/500\n",
      "23895/23895 [==============================] - 7s 305us/step - loss: 0.1538 - acc: 0.9896 - val_loss: 5.3376 - val_acc: 0.9035\n",
      "Epoch 195/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1521 - acc: 0.9897 - val_loss: 5.5179 - val_acc: 0.9004\n",
      "Epoch 196/500\n",
      "23895/23895 [==============================] - 8s 314us/step - loss: 0.1648 - acc: 0.9889 - val_loss: 5.4961 - val_acc: 0.9022\n",
      "Epoch 197/500\n",
      "23895/23895 [==============================] - 8s 321us/step - loss: 0.1742 - acc: 0.9874 - val_loss: 5.5468 - val_acc: 0.8980\n",
      "Epoch 198/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.1055 - acc: 0.9908 - val_loss: 6.0294 - val_acc: 0.9072\n",
      "Epoch 199/500\n",
      "23895/23895 [==============================] - 7s 313us/step - loss: 0.1724 - acc: 0.9891 - val_loss: 5.5646 - val_acc: 0.9001\n",
      "Epoch 200/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1499 - acc: 0.9892 - val_loss: 5.6006 - val_acc: 0.9043\n",
      "Epoch 201/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1729 - acc: 0.9895 - val_loss: 5.3485 - val_acc: 0.9000\n",
      "Epoch 202/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1440 - acc: 0.9913 - val_loss: 5.4113 - val_acc: 0.9017\n",
      "Epoch 203/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1626 - acc: 0.9882 - val_loss: 5.2698 - val_acc: 0.8971\n",
      "Epoch 204/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1453 - acc: 0.9904 - val_loss: 5.7729 - val_acc: 0.9023\n",
      "Epoch 205/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.2218 - acc: 0.9876 - val_loss: 5.1849 - val_acc: 0.8965\n",
      "Epoch 206/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1712 - acc: 0.9896 - val_loss: 5.2102 - val_acc: 0.8987\n",
      "Epoch 207/500\n",
      "23895/23895 [==============================] - 8s 320us/step - loss: 0.1627 - acc: 0.9896 - val_loss: 5.3381 - val_acc: 0.9053oss: 0.1614 - acc:\n",
      "Epoch 208/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.1562 - acc: 0.9886 - val_loss: 5.4522 - val_acc: 0.9050\n",
      "Epoch 209/500\n",
      "23895/23895 [==============================] - 8s 315us/step - loss: 0.1405 - acc: 0.9902 - val_loss: 5.8454 - val_acc: 0.9038\n",
      "Epoch 210/500\n",
      "23895/23895 [==============================] - 8s 317us/step - loss: 0.1433 - acc: 0.9897 - val_loss: 5.6762 - val_acc: 0.9036\n",
      "Epoch 211/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1476 - acc: 0.9908 - val_loss: 5.3564 - val_acc: 0.8924\n",
      "Epoch 212/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1488 - acc: 0.9900 - val_loss: 5.3320 - val_acc: 0.8983\n",
      "Epoch 213/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1816 - acc: 0.9892 - val_loss: 4.9938 - val_acc: 0.8972\n",
      "Epoch 214/500\n",
      "23895/23895 [==============================] - 7s 313us/step - loss: 0.1521 - acc: 0.9900 - val_loss: 5.2716 - val_acc: 0.9019\n",
      "Epoch 215/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1629 - acc: 0.9905 - val_loss: 5.4369 - val_acc: 0.9010\n",
      "Epoch 216/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1743 - acc: 0.9891 - val_loss: 5.4416 - val_acc: 0.9019\n",
      "Epoch 217/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1749 - acc: 0.9893 - val_loss: 5.1965 - val_acc: 0.8960\n",
      "Epoch 218/500\n",
      "23895/23895 [==============================] - 7s 313us/step - loss: 0.1575 - acc: 0.9894 - val_loss: 5.4805 - val_acc: 0.8941\n",
      "Epoch 219/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1435 - acc: 0.9910 - val_loss: 5.4979 - val_acc: 0.8947\n",
      "Epoch 220/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1696 - acc: 0.9890 - val_loss: 5.4903 - val_acc: 0.8987\n",
      "Epoch 221/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1679 - acc: 0.9890 - val_loss: 5.3064 - val_acc: 0.8984\n",
      "Epoch 222/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1618 - acc: 0.9915 - val_loss: 5.2462 - val_acc: 0.8982\n",
      "Epoch 223/500\n",
      "23895/23895 [==============================] - 8s 317us/step - loss: 0.1526 - acc: 0.9914 - val_loss: 5.2278 - val_acc: 0.8951\n",
      "Epoch 224/500\n",
      "23895/23895 [==============================] - 8s 324us/step - loss: 0.1289 - acc: 0.9921 - val_loss: 5.3940 - val_acc: 0.8984\n",
      "Epoch 225/500\n",
      "23895/23895 [==============================] - 8s 319us/step - loss: 0.1598 - acc: 0.9910 - val_loss: 4.9735 - val_acc: 0.8944\n",
      "Epoch 226/500\n",
      "23895/23895 [==============================] - 8s 322us/step - loss: 0.1695 - acc: 0.9897 - val_loss: 5.4166 - val_acc: 0.8968\n",
      "Epoch 227/500\n",
      "23895/23895 [==============================] - 8s 324us/step - loss: 0.1698 - acc: 0.9918 - val_loss: 5.7049 - val_acc: 0.9005\n",
      "Epoch 228/500\n",
      "23895/23895 [==============================] - 8s 318us/step - loss: 0.1384 - acc: 0.9910 - val_loss: 5.6553 - val_acc: 0.9073\n",
      "Epoch 229/500\n",
      "23895/23895 [==============================] - 8s 320us/step - loss: 0.1613 - acc: 0.9901 - val_loss: 5.4019 - val_acc: 0.9041\n",
      "Epoch 230/500\n",
      "23895/23895 [==============================] - 7s 313us/step - loss: 0.1613 - acc: 0.9892 - val_loss: 5.5274 - val_acc: 0.8980\n",
      "Epoch 231/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1567 - acc: 0.9886 - val_loss: 5.4061 - val_acc: 0.9014\n",
      "Epoch 232/500\n",
      "23895/23895 [==============================] - 7s 310us/step - loss: 0.1370 - acc: 0.9903 - val_loss: 5.5325 - val_acc: 0.9047\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1986 - acc: 0.9898 - val_loss: 5.5221 - val_acc: 0.9017\n",
      "Epoch 234/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1773 - acc: 0.9875 - val_loss: 5.4036 - val_acc: 0.9053\n",
      "Epoch 235/500\n",
      "23895/23895 [==============================] - 7s 303us/step - loss: 0.1643 - acc: 0.9891 - val_loss: 5.4987 - val_acc: 0.9032\n",
      "Epoch 236/500\n",
      "23895/23895 [==============================] - 7s 303us/step - loss: 0.1548 - acc: 0.9902 - val_loss: 5.5572 - val_acc: 0.9035\n",
      "Epoch 237/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1445 - acc: 0.9918 - val_loss: 5.2932 - val_acc: 0.9020\n",
      "Epoch 238/500\n",
      "23895/23895 [==============================] - 7s 305us/step - loss: 0.1487 - acc: 0.9915 - val_loss: 5.3485 - val_acc: 0.9029\n",
      "Epoch 239/500\n",
      "23895/23895 [==============================] - 7s 305us/step - loss: 0.1236 - acc: 0.9916 - val_loss: 5.6529 - val_acc: 0.9046\n",
      "Epoch 240/500\n",
      "23895/23895 [==============================] - 7s 305us/step - loss: 0.1427 - acc: 0.9913 - val_loss: 5.7293 - val_acc: 0.9029\n",
      "Epoch 241/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1791 - acc: 0.9898 - val_loss: 5.3058 - val_acc: 0.9018\n",
      "Epoch 242/500\n",
      "23895/23895 [==============================] - 7s 303us/step - loss: 0.1507 - acc: 0.9908 - val_loss: 5.5612 - val_acc: 0.9050\n",
      "Epoch 243/500\n",
      "23895/23895 [==============================] - 7s 303us/step - loss: 0.1574 - acc: 0.9917 - val_loss: 5.4784 - val_acc: 0.8987\n",
      "Epoch 244/500\n",
      "23895/23895 [==============================] - 8s 314us/step - loss: 0.1519 - acc: 0.9910 - val_loss: 5.5371 - val_acc: 0.9012\n",
      "Epoch 245/500\n",
      "23895/23895 [==============================] - 8s 317us/step - loss: 0.1327 - acc: 0.9930 - val_loss: 5.6005 - val_acc: 0.9000\n",
      "Epoch 246/500\n",
      "23895/23895 [==============================] - 8s 321us/step - loss: 0.1158 - acc: 0.9928 - val_loss: 5.9448 - val_acc: 0.8954\n",
      "Epoch 247/500\n",
      "23895/23895 [==============================] - 7s 304us/step - loss: 0.1982 - acc: 0.9886 - val_loss: 5.5445 - val_acc: 0.8975\n",
      "Epoch 248/500\n",
      "23895/23895 [==============================] - 7s 309us/step - loss: 0.1353 - acc: 0.9925 - val_loss: 5.6775 - val_acc: 0.9006\n",
      "Epoch 249/500\n",
      "23895/23895 [==============================] - 7s 311us/step - loss: 0.1615 - acc: 0.9911 - val_loss: 5.8081 - val_acc: 0.9025\n",
      "Epoch 250/500\n",
      "23895/23895 [==============================] - 8s 344us/step - loss: 0.1548 - acc: 0.9919 - val_loss: 5.5950 - val_acc: 0.9015\n",
      "Epoch 251/500\n",
      "23895/23895 [==============================] - 8s 321us/step - loss: 0.1632 - acc: 0.9913 - val_loss: 5.9241 - val_acc: 0.9069\n",
      "Epoch 252/500\n",
      "23895/23895 [==============================] - 8s 339us/step - loss: 0.1423 - acc: 0.9926 - val_loss: 5.8244 - val_acc: 0.9025\n",
      "Epoch 253/500\n",
      "23895/23895 [==============================] - 8s 320us/step - loss: 0.1558 - acc: 0.9910 - val_loss: 5.6720 - val_acc: 0.9026\n",
      "Epoch 254/500\n",
      "23895/23895 [==============================] - 7s 303us/step - loss: 0.1504 - acc: 0.9900 - val_loss: 5.8000 - val_acc: 0.9037\n",
      "Epoch 255/500\n",
      "23895/23895 [==============================] - 7s 301us/step - loss: 0.1587 - acc: 0.9903 - val_loss: 5.4409 - val_acc: 0.9010\n",
      "Epoch 256/500\n",
      "23895/23895 [==============================] - 8s 337us/step - loss: 0.1493 - acc: 0.9913 - val_loss: 5.6304 - val_acc: 0.9017\n",
      "Epoch 257/500\n",
      "23895/23895 [==============================] - 8s 334us/step - loss: 0.1573 - acc: 0.9914 - val_loss: 5.7146 - val_acc: 0.8976\n",
      "Epoch 258/500\n",
      "23895/23895 [==============================] - 8s 331us/step - loss: 0.1638 - acc: 0.9893 - val_loss: 5.5182 - val_acc: 0.8980\n",
      "Epoch 259/500\n",
      "23895/23895 [==============================] - 8s 329us/step - loss: 0.1739 - acc: 0.9886 - val_loss: 5.5439 - val_acc: 0.8946\n",
      "Epoch 260/500\n",
      "23895/23895 [==============================] - 8s 331us/step - loss: 0.1785 - acc: 0.9904 - val_loss: 5.2954 - val_acc: 0.8963\n",
      "Epoch 261/500\n",
      " 5024/23895 [=====>........................] - ETA: 5s - loss: 0.1313 - acc: 0.9918"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-455b66e14ae9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m23.3\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class_weight = {0: 1.,1: 23.3}\n",
    "history = model1.fit( X,label.values ,epochs=100, validation_split=0.3,class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0, 1: 23.3}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
